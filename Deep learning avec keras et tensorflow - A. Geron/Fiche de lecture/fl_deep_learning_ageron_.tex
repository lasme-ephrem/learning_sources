 %propriétés du livre 	-------------------------------------%
\documentclass[executivepaper]{article}
\usepackage{ae,lmodern}
%\usepackage{times}
\usepackage[french]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}

%formatage de l'interligne------------------------------%
\usepackage{setspace}
\onehalfspacing
\usepackage{hyperref}
%packages gestion de marge------------------------------%
\usepackage[top=2.5cm, bottom=2.5cm, left=2cm, right=2cm,
textheight=19cm]{geometry}

%packages titre des chapitres--------------------------%
%\usepackage[Glenn]{fncychap}
%\ChTitleVar{\huge\bfseries}

%package entête et pied de page------------------------%
\usepackage{fancyhdr}
\pagestyle{fancy}
\renewcommand{\headrulewidth}{1pt}
\fancyhead[L]{Fiche de lecture}
\fancyhead[R]{\textbf{\thepage}}
\renewcommand{\footrulewidth}{1pt}
\fancyfoot[C]{\small{\textsc{ESSOH Lasme Ephrem Dominique}}}

\renewcommand{\labelenumi}{\textbf{\textit{\arabic{enumi}}.} }

%packages de l'environnement mathématique-------------%
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{bbold}
\newcommand{\esperance}{\mathbb{E}}
\newcommand{\variance}{\mathbb{V}}
\newcommand{\reels}{\mathbb{R}}
\newcommand{\entiers}{\mathbb{N}}
\newcommand{\relatifs}{\mathbb{Z}}
\newcommand{\rationnels}{\mathbb{Q}}
\newcommand{\complexes}{\mathbb{C}}
\newcommand{\indicatrice}{\mathbb{1}}
\newcommand{\proba}{\mathbb{P}}
\newcommand{\tribu}{\mathcal{F}}
\newcommand{\trmes}{\mathcal{T}}
\newcommand{\ensp}{\mathcal{P}}
\newcommand{\borelien}{\mathcal{B}}
\usepackage{tabvar}
\usepackage{graphicx}
\usepackage {boxedminipage }

%package couleur des textes------------------------%
\usepackage{color}
%\setcounter{chapter}{-1}

%auteurs du livre---------------------------%

\title{\textbf{\Huge{Fiche de lecture : Deep Learning avec Keras et Tensorflow, Aurélien Géron}}}
\author{\textsc{Essoh Lasme Ephrem Dominique}}



\begin{document}
	
\maketitle

	\section{Avant-propos}

\begin{itemize}


\item Aujourd'hui les progrès réalisés par l'IA sont énormes et continues de nous épater : nous communiquons avec l'assistant virtuel de notre téléphone, nous avons déjà été interpellé par un système de recommandation quelconque d'un site de vente en ligne, des voitures autonomes sillonnent déjà les rues des USA, Alpha Go bat le champion du monde au jeu de Go ... en fait, ce qui était impossible il y a de cela 10 ans est devenu une réalité quotidienne et on se demande ce qu'il adviendra à l'avenir en terme de prouesses : \textbf{l'intelligence artificielle est en pleine expansion}.\\~\

\item Au coeur des progrès observés dans le domaine de l'IA se trouve le Machine Learning. C'est la capacité de programmer des systèmes qui apprennent automatiquement. Bien qu'existant depuis très longtemps ce n'est que récemment que l'usage du ML s'est considérablement démocratisé : Passant par le monde de la recherche universitaire, c'est à travers les GAFA qu'il est beaucoup utilisé et fait parlé de lui. Aujourd'hui, toutes les entreprises vivent le ML pour l'extraction de connaissances dans les données qu'elles produisent chaque jour.\\~\
\item  Trois raisons essentielles justifient cette démocratisation : (i) la transformation digitale de quasiment toutes les entreprises qui produisent ainsi des données au jour le jour et qui peuvent devenir volumineuse, (ii) l'accroissement de la puissance de calcul de nos ordinateurs et(iii)l'existence d'une très vaste communauté scientifique et grandissante.\\~\

\item Le ML c'est l'assemblage de plusieurs disciplines et outils dont le Deep Learning fait beaucoup parlé de lui. Le DL est fondé sur les réseaux de neurones artificiels. Il s'est fait connaitre principalement en 2006 avec Goeffrey Hinton et son équipe de recherche, bien que les investigations sur les RNA aient été entamées par de nombreux chercheurs il y a bien longtemps et même abandonné sur certaines périodes au profit d'autre méthodes de prédiction car ne disposant des conditions requises pour leur apprentissage. 
\end{itemize}

\section{Chapitre 1 : Les fondamentaux du Machine Learning}

\begin{itemize}
\item Bien que relevant de très bonnes doses théoriques, le Machine Learning et le Deep Learning s'apprennent surtout par la Pratique ;\\
\item Importance et utilité de savoir manipuler des environnements de programmation pour de projet ML avec anaconda. Les environnements peuvent se créer directement dans anaconda ou à travers la ligne de commande. Mais on peut aussi créer un environnement à partir d'un fichier d'extension .yml déjà existant. Exemple installation de l'environnement tf2 qui comprends tous les modules utilisés du livre ;\\
\item Le Machine Learning est la science et l'art de programmer des ordinateurs de sorte qu'il puisse apprendre à partir des données ;\\
\item A. Samuel : \textit{C'est la discipline donnant aux ordinateurs la possibilité d'apprendre sans être explicitement programmés} ;\\
\item T. Mitchell : \textit{Etant donnée une tâche T et une mesure de performance P, on dit qu'un programme informatique apprend à partir d'une expérience E si les résultats obtenus sur  T, mesurés par P, s'améliorent avec l'expérience E.}\\
\item Plusieurs formes de ML : 
\begin{enumerate}
\item Apprentissage supervisé : Classification, Régression
\item Apprentissage non-supervisé : Réduction de dimension, Partitionnement, Détection d'anomalie
\item Apprentissage par renforcement : Programmation d'un agent (le système intelligent ou robot) interagissant avec un environnement.\\

\end{enumerate}
\item Quelque soit le type de ML, un système de ML (ou d'apprentissage) passe (toujours) par deux étapes en général :
\begin{enumerate}
\item La phase d'entrainement : il est entrainé sur un jeu de donnée d'entrainement appelé training set ;
\item La phase d'inférence ou de généralisation :  il applique ce qu'il a appris sur de nouvelles données appelées testing set.
\end{enumerate}
\item Attention, il existe plusieurs variantes de ce schéma d'apprentissage mais le principe reste le même.\\
\item Illustrons la façon dont un système apprend à l'aide de la  tâche de prédiction (Apprentissage supervisé) : 

\begin{enumerate}
\item On souhaite construire un modèle qui s'ajuste au mieux à nos données d'entrainement sans trop y coller ;
\item Choisir un espace de fonctions hypothèses ou modèles ou prédicteurs ;
\item Définir une mesure de performance à travers une fonction de coût ;
\item Rechercher l'hypothèse optimal ou le modèle qui s'ajuste au mieux aux données par minimisation du coût/risque moyen ;
\item Cette recherche conduit à ajuster au fur et à mesure les paramètres du modèle de sorte à trouver les plus optimaux ; 
\item Évaluer la performance de généralisation du modèle optimal sur de nouvelles données et en juger de la qualité.\\


En fin de compte la tâche d'apprentissage se résume en un problème d'optimisation de fonction. Suivant la tâche à resoudre, ce problème peut avoir une solution analytique ou pas. Dans le second cas, le principe d'apprentissage est plus perceptible dans la mesure où l'algorithme d'optimisation que nous utilisons traduit à travers des hyperamètres l'intuition d'apprentissage.\\

\end{enumerate}

\item Selon les auteurs, la notion de fonction de coût ou de perte peut désigner la perte encourue par un prédicteur sur une observation ou la perte moyenne encourue par un prédicteur sur l'ensemble des observation. Aurélien Géron utilise le terme de fonction de coût dans le second cas.\\


\item Dans l'exemple de la régression linéaire, disposant d'un jeu de données d'entrainement, on souhaite produire une meilleure prédiction sur de nouvelles données. L'espace des fonctions hypothèses choisi est celui des fonctions linéaires (droite dans le cas d'une seule feature). Ensuite, on définit le coût quadratique comme étant la différence \og au carrée \fg{} entre la vraie étiquette et sa valeur prédite. Dans ce cas, le coût ou risque moyen est la moyenne empirique de toutes les pertes calculées sur les observations : c'est ce que l'on appelle l'erreur quadratique moyenne. Sa racine carrée, nous fournit l'erreur de prédiction moyenne commise. On cherche alors la meilleure fonction, dans l'espace d'hypothèse, qui minimise cette erreur moyenne, c'est le principe de minimisation du risque empirique. Le programme informatique ou algorithme de minimisation de cette erreur moyenne décrit le processus d'apprentissage : l'algorithme que nous utilisons pour minimiser le coût, utilise les données pour trouver les bons paramètres. Par exemple, l'algorithme de calcul de l'équation normale directement ou par pseudo-inverse, un système d'apprentissage, qui nous fournit les paramètres optimaux. \\~\

\item \textbf{La descente de gradient, un point angulaire du procédure d'apprentissage :} Notons que dans le cas de la régression le processus d'apprentissage par équation normal produit une complexité algorithmique qui augmente avec le nombre de variables du jeu de données d'entrainement. Si le nombre de variable est très important ($>10^{1000}$ par exemple) l'algorithme prendra du temps pour apprendre les paramètres ! Cependant même quand le nombre d'observation est très important, une fois les paramètres appris, la prédiction sur de nouvelle données se fait rapidement puisque la complexité est faible.\\

Comme en ML on traite de données qui sont relativement importantes en nombre de variables et d'observation (grosses données), on souhaite produit des processus d'apprentissage les plus efficients en terme de complexité ou de temps de calculs. La descente de gradient et ses variantes sont alors très utilisés en ML.\\

L'algorithme de descente de gradient est un algorithme qui permet de trouver l'optimum d'un programme d'optimisation. Son principe consiste à donner une valeur initiale (aléatoire ou pas) au vecteur de paramètres, à calculer le gradient du risque empirique en le vecteur de paramètres, à définir un nombre d'itération de telle sorte que à chaque itération on retire du vecteur de paramètre une fraction du gradient calculé à un facteur près (appelé taux d'apprentissage) de sorte à atteindre le minimum du coût empirique. Il convient pour la minimisation du risque empirique. Si pour une étape d'itération donnée, le gradient est nulle alors on a atteint un minimum ! Toutefois ce minimum n'est pas nécessaire un minimum global. Mais dans le cas d'un problème d'optimisation convexe, nous somme sûr du fait que ce minimum est global.\\

$$\theta^{etape suivante} = \theta^{etape actuelle} - \eta \cdot \nabla_\theta REM(\theta)$$
$$ \:\: \text{pour une certaine valeur initiale} \:\: \theta_0 \:\: \text{de} \:\: \theta \:\: \text{et un nombre d'itération} \:\: n \:\: \text{donné} $$

Il faut donc fournir trois objets pour réaliser une descente de gradient : \\

(i) la valeur initiale du paramètre $\theta_0$ qui ne pose aucun problème, car on peut même l'initialiser au hasard ;\\
 
 (ii) le nombre d'itération $n$ a effectué. Attention si on choisit un nombre d'itération trop petit on peut atteindre une valeur qui n'est pas l'optimum car on a interrompu l'algorithme d'apprentissage avant, de même si on choisit un nombre d'itération trop grand on peut atteindre l'optimum et dans ce cas les itérations suivantes ne sont d'aucune utilité. Alors comment choisir ce nombre d'itération ? Une solution simple consiste à choisir un très grand nombre d'itération et a arrêté l'algorithme quand le vecteur gradient devient très petit, c'est-à-dire quand sa norme devient inférieur à un très petit nombre $\varepsilon$. Ce qui traduit que la descente de gradient a presque atteint un minimum. Naturellement, plus ce $\varepsilon$ est petit plus le résultat est précis (cependant plus on devra attendre la fin). En général les modules d'apprentissage utilisés gèrent le choix de $n$, mais il peut arrivé qu'on soit amené a choisir $n$.\\
 
 (iii) le taux d'apprentissage $\eta$, qui est le vrai et seul hyperparamètre qui est choisi idéalement par la technique de validation croisée.\\
 

On appelle hyperparamètre un paramètre de l'algorithme d'apprentissage et non un paramètre du modèle. Le paramètre du modèle est appris alors que l'hyperparamètre est fixé avant de lancé l'algorithme d'apprentissage.\\

De fait, plusieurs valeur de cet hyperparamètre peuvent être testées afin de sélectionner le meilleur. D'ailleurs, la validation croisée utilise ce principe.\\

Attention un algorithme d'apprentissage peut posséder plusieurs hyperparamètres.\\

Petite digression, la notion d'hyperparamètre nous permet de faire des distinctions très importantes : il ne faut jamais confondre modèle ou prédicteur (régresseur ou classifieur) et algorithme (d'apprentissage). C'est l'algorithme qui produit le modèle à travers un processus d'apprentissage à partir des données (que l'on a exposé   des nos lignes ci-dessus). Le modèle est ensuite utilisé pour résoudre une tâche.\\

TACHE A RÉSOUDRE $\longrightarrow$ DONNÉES $\longrightarrow$ ALGORITHME APPRENTISSAGE $\longrightarrow$ MODÈLE $\longrightarrow$ TACHE RÉSOLUE.\\

La descente de gradient possède l'avantage d'être très rapide même quand le nombre de variables est très très important. Cependant, selon le nombre d'observation utilisé pour le calcul du gradient $\nabla_\theta REM(\theta)$ la complexité de l'algorithme peut augmenté avec ce nombre. C'est justement de là que provient les différentes variantes de la descente de gradient.Chacune ayant une utilité bien spécifique : celle de nous faire gagner du temps lorsque nous apprenons un prédicteur tout ayant une plus ou moins bonne précision des résultats.\\

Une descente de gradient qui utilise toutes les observations pour calculer le vecteur gradient à chaque itération est appelée descente de gradient groupée ou descente de gradient ordinaire ou \textit{batch gradient descent} en anglais. Elle a l'avantage d'être précise en terme de résultat obtenu cependant elle peut être très lente sur un jeu de données qui contient un trop grand nombre d'observation : sa complexité augmente donc avec le nombre d'observation. Et aussi, elle plus enclin a atteindre un minimum local que global lorsque notre risque empirique moyen est une fonction non-convexe (pas la forme d'un bol) c'est-à-dire irrégulière.\\

Une descente de gradient qui utilise une et une seule observation, et ce de manière aléatoire (tirage aléatoire), pour calculer le vecteur gradient à chaque itération est appelée descente de gradient stochastique ou \textit{stochastic gradient descent} en anglais. Elle a l'avantage d'être très rapide et efficace même sur un très grand jeu de données puisque ne nécessitant qu'une seule observation pour une itération. Cependant sa nature aléatoire fait qu'elle oscille autour du minimum recherché sans toutefois l'atteindre. Ce qui est bien c'est qu'elle peut nous permet d'éviter des minimums locaux de par ses oscillations. Lors de son entrainement, l'une des technique est alors de modifier progressivement le taux d'apprentissage, à chaque itération, en le faisant baisser/augmenter au fur et à mesure de sorte à sauter les minimums locaux et s'approcher du minimum global (technique de l'échéancier d'apprentissage ou du refroidissement lent du métal en fusion).


Prenez garde à toujours normaliser vos données lorsque vous devez appliquer une descente de gradient quel qu'elle soit !\\


\item 

\end{itemize}

\end{document}